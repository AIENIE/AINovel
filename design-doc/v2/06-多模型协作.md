# 多模型协作

## 文档信息

| 字段 | 值 |
|------|-----|
| 版本 | v2.0 |
| 日期 | 2026-02-17 |
| 优先级 | P3 |
| 关联模块 | 01-上下文记忆, 02-风格画像, 03-Beta-Reader |

---

## 1. 背景与动机

### 1.1 问题陈述

v1 版本的 AI 调用链路为 `AiController` -> `AiService` -> `AiGatewayGrpcClient.chatCompletions()`，全局使用单一模型完成所有任务。当前 `AiService.chat()` 的模型选择逻辑极为简单：

```java
// AiService.java 当前逻辑
String model = request.modelId();
if (model == null || model.isBlank()) {
    List<AiModelDto> models = listModels();
    if (!models.isEmpty()) {
        model = models.get(0).id(); // 直接取第一个可用模型
    }
}
```

这种"一刀切"的模型策略带来以下问题：

1. **任务-模型不匹配**：创意写作（故事生成、正文续写）需要想象力强、文笔好的模型；实体提取、连续性检查等分析任务需要逻辑严谨、指令遵循度高的模型；Embedding 任务需要专用的向量模型。用同一个模型处理所有任务，必然在某些维度上妥协。

2. **语言能力差异被忽略**：部分模型在中文创作上表现优异（如 DeepSeek、Qwen），部分模型在英文叙事上更强（如 Claude、GPT-4o）。当前系统无法根据作品语言选择最优模型。

3. **成本不可控**：高端模型（Claude Opus、GPT-4o）适合关键创作任务，但用于简单的摘要生成或格式化处理则浪费预算。用户无法感知不同操作的成本差异。

4. **无容错机制**：当前 `AiGatewayGrpcClient` 调用失败后直接抛出异常，没有备选模型降级策略。单一模型的服务中断会导致整个写作流程阻塞。

5. **无法对比评估**：用户无法在同一任务上对比不同模型的输出质量，只能盲目信任系统默认选择。

6. **用户偏好缺失**：不同用户对模型有不同偏好——有人追求质量不计成本，有人希望快速廉价完成初稿。当前系统没有个性化模型配置能力。

### 1.2 业界参考

| 产品/方案 | 核心机制 | 借鉴点 |
|-----------|----------|--------|
| **OpenRouter** | 统一 API 网关，支持按模型路由、自动 fallback、成本追踪；提供 `/models` 端点返回模型能力标签和定价 | 模型注册表设计、能力标签体系、fallback 链 |
| **Cursor** | 编辑器内置多模型切换（Claude/GPT/自定义），不同功能默认使用不同模型（Tab 补全用快速模型，Agent 用强模型） | 任务-模型绑定策略、用户可覆盖默认值 |
| **Vercel AI SDK** | `experimental_generateText` 支持 `model` 参数动态切换，`ModelRegistry` 管理多 provider | SDK 层面的模型抽象、provider 统一接口 |
| **LiteLLM** | 统一代理层，支持 100+ 模型 provider，内置 load balancing、fallback、cost tracking | 统一调用接口、负载均衡、成本日志 |
| **Dify** | 工作流编排中每个节点可独立选择模型，支持模型能力标签和自动推荐 | 节点级模型选择、能力标签匹配 |

---

## 2. 设计目标

1. **任务级模型路由**：根据任务类型（故事生成、大纲编排、正文续写、润色、实体提取、风格分析、Beta Reader 审读、连续性检查、Embedding、摘要生成）自动选择最优模型，每种任务类型可独立配置推荐模型。

2. **能力标签体系**：为每个模型标注能力标签（`creative_writing`、`analysis`、`extraction`、`chinese`、`english`、`fast`、`cheap`、`long_context`、`structured_output`），支持基于标签的智能匹配。

3. **系统默认推荐**：系统为每种任务类型预设推荐模型，开箱即用，用户无需手动配置即可获得合理的模型分配。

4. **用户偏好覆盖**：用户可在设置中为每种任务类型指定偏好模型，覆盖系统默认推荐。设为空则回退到系统默认。

5. **Fallback 降级链**：每条路由规则可配置备选模型。当主模型调用失败（超时、限流、服务不可用）时，自动切换到备选模型，保证写作流程不中断。

6. **成本感知**：在生成前展示预估成本（基于输入 Token 估算），在生成后记录实际消耗。用户可查看按模型、按任务类型的用量统计。

7. **A/B 对比生成**：用户可选择两个模型对同一任务并行生成，侧边栏对比输出结果，选择更满意的版本。

8. **与 ai-service 同步**：模型注册表通过 `AiGatewayGrpcClient.listModels()` 与 AIENIE ai-service 保持同步，新模型上线后自动发现。

---

## 3. 详细设计

### 3.1 数据模型

#### 3.1.1 ER 关系

```
model_registry 1──N task_model_routing (recommended_model_id)
model_registry 1──N task_model_routing (fallback_model_id)
model_registry 1──N user_model_preferences (preferred_model_id)
model_registry 1──N model_usage_logs (model_id)
users          1──N user_model_preferences (user_id)
users          1──N model_usage_logs (user_id)
stories        1──N model_usage_logs (story_id)
```

#### 3.1.2 DDL

```sql
-- ============================================================
-- 模型注册表：记录所有可用 AI 模型的元信息与能力标签
-- ============================================================
CREATE TABLE model_registry (
    id              CHAR(36)        NOT NULL    COMMENT '主键 UUID',
    model_key       VARCHAR(100)    NOT NULL    COMMENT '模型唯一标识，如 claude-3-opus, gpt-4o, deepseek-v3',
    display_name    VARCHAR(200)    NOT NULL    COMMENT '前端展示名称',
    provider        VARCHAR(50)     NOT NULL    COMMENT '模型提供方，如 anthropic, openai, deepseek',
    capabilities_json TEXT          NULL        COMMENT '能力标签 JSON 数组，如 ["creative_writing","chinese","long_context"]',
    max_context_tokens  INT             NOT NULL DEFAULT 0       COMMENT '最大上下文 Token 数',
    max_output_tokens   INT             NOT NULL DEFAULT 0       COMMENT '最大输出 Token 数',
    cost_per_1k_input   DECIMAL(10,6)   NOT NULL DEFAULT 0       COMMENT '每千输入 Token 成本（美元）',
    cost_per_1k_output  DECIMAL(10,6)   NOT NULL DEFAULT 0       COMMENT '每千输出 Token 成本（美元）',
    supports_streaming  BOOLEAN         NOT NULL DEFAULT TRUE    COMMENT '是否支持流式输出',
    is_available        BOOLEAN         NOT NULL DEFAULT TRUE    COMMENT '是否当前可用',
    priority            INT             NOT NULL DEFAULT 0       COMMENT '排序优先级，数值越大越靠前',
    created_at          TIMESTAMP       NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at          TIMESTAMP       NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY (id),
    UNIQUE KEY uk_model_key (model_key),
    INDEX idx_provider (provider),
    INDEX idx_available_priority (is_available, priority DESC)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
  COMMENT='模型注册表';

-- ============================================================
-- 任务模型路由：定义每种任务类型的推荐模型与降级策略
-- ============================================================
CREATE TABLE task_model_routing (
    id                      CHAR(36)        NOT NULL    COMMENT '主键 UUID',
    task_type               VARCHAR(50)     NOT NULL    COMMENT '任务类型枚举值',
    recommended_model_id    CHAR(36)        NOT NULL    COMMENT '推荐模型 FK -> model_registry',
    fallback_model_id       CHAR(36)        NULL        COMMENT '备选模型 FK -> model_registry（可空）',
    routing_strategy        VARCHAR(30)     NOT NULL DEFAULT 'fixed'
                            COMMENT '路由策略: fixed / capability_match / cost_optimized / quality_optimized',
    config_json             TEXT            NULL        COMMENT '策略附加配置 JSON',
    created_at              TIMESTAMP       NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at              TIMESTAMP       NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY (id),
    UNIQUE KEY uk_task_type (task_type),
    CONSTRAINT fk_routing_recommended FOREIGN KEY (recommended_model_id) REFERENCES model_registry(id),
    CONSTRAINT fk_routing_fallback    FOREIGN KEY (fallback_model_id)    REFERENCES model_registry(id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
  COMMENT='任务模型路由表';

-- task_type 枚举值说明：
-- story_generation    故事构思生成
-- chapter_outline     章节大纲编排
-- manuscript_writing  正文续写
-- refine              文本润色
-- entity_extraction   实体提取（上下文记忆模块）
-- style_analysis      风格分析（风格画像模块）
-- beta_reader         Beta Reader 审读
-- continuity_check    连续性检查
-- embedding           文本向量化
-- summarization       摘要生成

-- ============================================================
-- 用户模型偏好：用户可覆盖系统默认的任务-模型映射
-- ============================================================
CREATE TABLE user_model_preferences (
    id                  CHAR(36)        NOT NULL    COMMENT '主键 UUID',
    user_id             CHAR(36)        NOT NULL    COMMENT '用户 FK -> users',
    task_type           VARCHAR(50)     NOT NULL    COMMENT '任务类型',
    preferred_model_id  CHAR(36)        NULL        COMMENT '偏好模型 FK -> model_registry（NULL 表示使用系统默认）',
    created_at          TIMESTAMP       NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at          TIMESTAMP       NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY (id),
    UNIQUE KEY uk_user_task (user_id, task_type),
    CONSTRAINT fk_pref_model FOREIGN KEY (preferred_model_id) REFERENCES model_registry(id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
  COMMENT='用户模型偏好表';

-- ============================================================
-- 模型使用日志：记录每次 AI 调用的模型、Token、成本、延迟
-- ============================================================
CREATE TABLE model_usage_logs (
    id              CHAR(36)        NOT NULL    COMMENT '主键 UUID',
    user_id         CHAR(36)        NOT NULL    COMMENT '用户 FK -> users',
    story_id        CHAR(36)        NULL        COMMENT '关联故事 FK -> stories（可空）',
    model_id        CHAR(36)        NOT NULL    COMMENT '实际使用模型 FK -> model_registry',
    task_type       VARCHAR(50)     NOT NULL    COMMENT '任务类型',
    input_tokens    INT             NOT NULL DEFAULT 0   COMMENT '输入 Token 数',
    output_tokens   INT             NOT NULL DEFAULT 0   COMMENT '输出 Token 数',
    latency_ms      INT             NOT NULL DEFAULT 0   COMMENT '调用延迟（毫秒）',
    cost_estimate   DECIMAL(10,6)   NOT NULL DEFAULT 0   COMMENT '预估成本（美元）',
    success         BOOLEAN         NOT NULL DEFAULT TRUE COMMENT '是否成功',
    error_message   TEXT            NULL        COMMENT '失败时的错误信息',
    created_at      TIMESTAMP       NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (id),
    INDEX idx_user_created (user_id, created_at DESC),
    INDEX idx_story (story_id),
    INDEX idx_model_task (model_id, task_type),
    INDEX idx_created (created_at DESC),
    CONSTRAINT fk_usage_model FOREIGN KEY (model_id) REFERENCES model_registry(id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
  COMMENT='模型使用日志表';
```

#### 3.1.3 能力标签枚举

| 标签 | 含义 | 典型模型 |
|------|------|----------|
| `creative_writing` | 创意写作能力强 | Claude Opus, GPT-4o |
| `analysis` | 逻辑分析与推理 | Claude Sonnet, GPT-4o |
| `extraction` | 结构化信息提取 | Claude Sonnet, Gemini Flash |
| `chinese` | 中文理解与生成优秀 | DeepSeek-V3, Qwen-Max |
| `english` | 英文理解与生成优秀 | Claude Opus, GPT-4o |
| `fast` | 响应速度快 | Gemini Flash, Claude Haiku |
| `cheap` | 成本低廉 | DeepSeek-V3, Gemini Flash |
| `long_context` | 支持超长上下文（>100K） | Claude Opus, Gemini Pro |
| `structured_output` | JSON/结构化输出稳定 | Claude Sonnet, GPT-4o |
| `embedding` | 向量嵌入专用 | text-embedding-3-large |

#### 3.1.4 初始数据示例

```sql
-- 示例：注册模型
INSERT INTO model_registry (id, model_key, display_name, provider, capabilities_json,
    max_context_tokens, max_output_tokens, cost_per_1k_input, cost_per_1k_output)
VALUES
    (UUID(), 'claude-3-opus', 'Claude 3 Opus', 'anthropic',
     '["creative_writing","analysis","english","long_context","structured_output"]',
     200000, 4096, 0.015000, 0.075000),
    (UUID(), 'claude-3-sonnet', 'Claude 3.5 Sonnet', 'anthropic',
     '["creative_writing","analysis","extraction","english","structured_output"]',
     200000, 8192, 0.003000, 0.015000),
    (UUID(), 'deepseek-v3', 'DeepSeek V3', 'deepseek',
     '["creative_writing","chinese","cheap","long_context"]',
     128000, 8192, 0.000270, 0.001100),
    (UUID(), 'gpt-4o', 'GPT-4o', 'openai',
     '["creative_writing","analysis","extraction","english","structured_output"]',
     128000, 16384, 0.002500, 0.010000),
    (UUID(), 'gemini-2-flash', 'Gemini 2.0 Flash', 'google',
     '["extraction","fast","cheap","structured_output"]',
     1000000, 8192, 0.000075, 0.000300);

-- 示例：任务路由（引用上面插入的模型 ID）
-- story_generation -> deepseek-v3（中文创作优先）, fallback -> claude-3-sonnet
-- entity_extraction -> gemini-2-flash（快速廉价）, fallback -> claude-3-sonnet
-- style_analysis -> claude-3-sonnet（分析能力强）, fallback -> gpt-4o
```

### 3.2 后端设计

#### 3.2.1 包结构

```
backend/src/main/java/com/ainovel/app/model/
├── ModelRoutingController.java      // REST API 控制器
├── ModelRegistryService.java        // 模型注册表管理（同步 ai-service）
├── ModelRoutingService.java         // 模型路由决策引擎
├── ModelPreferenceService.java      // 用户偏好管理
├── ModelUsageService.java           // 用量追踪与统计
├── AiOrchestrator.java              // AI 调用编排器（替代直接 AiService 调用）
├── entity/
│   ├── ModelRegistryEntity.java
│   ├── TaskModelRoutingEntity.java
│   ├── UserModelPreferenceEntity.java
│   └── ModelUsageLogEntity.java
├── dto/
│   ├── ModelInfoDto.java            // 模型信息（含能力标签、成本）
│   ├── TaskRoutingDto.java          // 路由规则
│   ├── ModelPreferenceDto.java      // 用户偏好
│   ├── ModelUsageSummaryDto.java    // 用量汇总
│   ├── GenerationRequest.java       // 统一生成请求
│   ├── GenerationResponse.java      // 统一生成响应
│   ├── ResolvedModel.java           // 路由决策结果
│   └── CompareModelsRequest.java    // A/B 对比请求
└── repo/
    ├── ModelRegistryRepository.java
    ├── TaskModelRoutingRepository.java
    ├── UserModelPreferenceRepository.java
    └── ModelUsageLogRepository.java
```

#### 3.2.2 核心类设计

**ResolvedModel — 路由决策结果**

```java
public record ResolvedModel(
    UUID modelId,
    String modelKey,
    String displayName,
    String provider,
    List<String> capabilities,
    String resolutionSource  // "user_preference" | "task_routing" | "default"
) {}
```

**ModelRoutingService — 模型路由决策引擎**

```java
@Service
public class ModelRoutingService {

    private final TaskModelRoutingRepository routingRepo;
    private final UserModelPreferenceRepository preferenceRepo;
    private final ModelRegistryRepository registryRepo;

    /**
     * 核心路由方法：根据任务类型和用户，决定使用哪个模型。
     * 优先级：用户偏好 > 任务路由规则 > 全局默认（第一个可用模型）
     */
    public ResolvedModel resolveModel(String taskType, UUID userId) {
        // 1. 检查用户偏好
        Optional<UserModelPreferenceEntity> pref =
            preferenceRepo.findByUserIdAndTaskType(userId, taskType);
        if (pref.isPresent() && pref.get().getPreferredModelId() != null) {
            ModelRegistryEntity model = registryRepo.findById(pref.get().getPreferredModelId())
                .filter(ModelRegistryEntity::isAvailable)
                .orElse(null);
            if (model != null) {
                return toResolved(model, "user_preference");
            }
        }

        // 2. 检查任务路由规则
        Optional<TaskModelRoutingEntity> routing =
            routingRepo.findByTaskType(taskType);
        if (routing.isPresent()) {
            ModelRegistryEntity model = registryRepo.findById(routing.get().getRecommendedModelId())
                .filter(ModelRegistryEntity::isAvailable)
                .orElse(null);
            if (model != null) {
                return toResolved(model, "task_routing");
            }
        }

        // 3. 全局默认：取优先级最高的可用模型
        ModelRegistryEntity fallback = registryRepo
            .findFirstByIsAvailableTrueOrderByPriorityDesc()
            .orElseThrow(() -> new IllegalStateException("无可用模型"));
        return toResolved(fallback, "default");
    }

    /**
     * 获取 fallback 模型（主模型失败时调用）
     */
    public Optional<ResolvedModel> resolveFallback(String taskType) {
        return routingRepo.findByTaskType(taskType)
            .map(TaskModelRoutingEntity::getFallbackModelId)
            .flatMap(registryRepo::findById)
            .filter(ModelRegistryEntity::isAvailable)
            .map(m -> toResolved(m, "fallback"));
    }
}
```

**AiOrchestrator — AI 调用编排器**

```java
@Service
public class AiOrchestrator {

    private final ModelRoutingService routingService;
    private final AiGatewayGrpcClient aiGatewayGrpcClient;
    private final ModelUsageService usageService;

    /**
     * 统一 AI 生成入口，替代原有 AiService 的直接调用。
     * 处理：模型选择 -> gRPC 调用 -> fallback -> 用量记录
     */
    public GenerationResponse generate(GenerationRequest request) {
        ResolvedModel model = routingService.resolveModel(
            request.taskType(), request.userId());

        long startMs = System.currentTimeMillis();
        try {
            AiGatewayGrpcClient.ChatResult result = aiGatewayGrpcClient
                .chatCompletions(request.remoteUid(), model.modelKey(), request.messages());

            long latencyMs = System.currentTimeMillis() - startMs;
            usageService.logUsage(request, model, result, latencyMs, true, null);

            return new GenerationResponse(
                result.content(), model, result.promptTokens(),
                result.completionTokens(), latencyMs);

        } catch (Exception e) {
            long latencyMs = System.currentTimeMillis() - startMs;
            usageService.logUsage(request, model, null, latencyMs, false, e.getMessage());

            // 尝试 fallback
            Optional<ResolvedModel> fallback = routingService
                .resolveFallback(request.taskType());
            if (fallback.isPresent()) {
                return generateWithModel(request, fallback.get());
            }
            throw e;
        }
    }

    /**
     * A/B 对比：用两个模型并行生成同一任务
     */
    public CompareModelsResponse compareModels(
            GenerationRequest request, String modelKeyA, String modelKeyB) {
        CompletableFuture<GenerationResponse> futureA =
            CompletableFuture.supplyAsync(() -> generateWithModelKey(request, modelKeyA));
        CompletableFuture<GenerationResponse> futureB =
            CompletableFuture.supplyAsync(() -> generateWithModelKey(request, modelKeyB));

        GenerationResponse responseA = futureA.join();
        GenerationResponse responseB = futureB.join();
        return new CompareModelsResponse(responseA, responseB);
    }
}
```

**ModelRegistryService — 模型注册表管理**

```java
@Service
public class ModelRegistryService {

    private final ModelRegistryRepository registryRepo;
    private final AiGatewayGrpcClient aiGatewayGrpcClient;

    /**
     * 从 ai-service 同步可用模型列表。
     * 对比本地注册表：新模型自动注册，已下线模型标记为不可用。
     */
    @Scheduled(fixedDelay = 300_000) // 每 5 分钟同步一次
    public void syncFromGateway() {
        List<AiModelDto> remoteModels = aiGatewayGrpcClient.listModels();
        Set<String> remoteKeys = new HashSet<>();

        for (AiModelDto remote : remoteModels) {
            remoteKeys.add(remote.id());
            Optional<ModelRegistryEntity> local = registryRepo.findByModelKey(remote.id());
            if (local.isEmpty()) {
                // 新模型：自动注册，能力标签待管理员补充
                ModelRegistryEntity entity = new ModelRegistryEntity();
                entity.setModelKey(remote.id());
                entity.setDisplayName(remote.displayName());
                entity.setProvider(remote.poolId());
                entity.setIsAvailable(remote.isEnabled());
                registryRepo.save(entity);
            } else {
                // 已有模型：更新可用状态
                ModelRegistryEntity entity = local.get();
                entity.setIsAvailable(remote.isEnabled());
                entity.setDisplayName(remote.displayName());
                registryRepo.save(entity);
            }
        }

        // 标记本地有但远端已下线的模型为不可用
        registryRepo.findByIsAvailableTrue().stream()
            .filter(m -> !remoteKeys.contains(m.getModelKey()))
            .forEach(m -> {
                m.setIsAvailable(false);
                registryRepo.save(m);
            });
    }
}
```

#### 3.2.3 调用流程

```
┌──────────────┐     ┌──────────────────┐     ┌─────────────────────┐
│ StoryService │     │  AiOrchestrator  │     │ ModelRoutingService │
│ WorldService │────>│                  │────>│                     │
│ ManuscriptSvc│     │  generate()      │     │  resolveModel()     │
└──────────────┘     └────────┬─────────┘     └──────────┬──────────┘
                              │                          │
                              │  1. 解析任务类型            │
                              │  2. 请求路由决策 ──────────>│
                              │  3. 返回 ResolvedModel <───│
                              │                          │
                              │  4. 调用 gRPC              │
                              ▼                          │
                     ┌──────────────────┐                │
                     │AiGatewayGrpcClient│                │
                     │ chatCompletions() │                │
                     └────────┬─────────┘                │
                              │                          │
                              │  5. 成功 → 记录用量        │
                              │  6. 失败 → resolveFallback │
                              │         → 重试 gRPC       │
                              ▼                          │
                     ┌──────────────────┐                │
                     │ ModelUsageService │                │
                     │  logUsage()      │                │
                     └──────────────────┘                │
```

### 3.3 API 设计

所有接口路径前缀为 `/api`，认证方式为 Bearer Token。

#### 3.3.1 模型注册表（公开 + 管理员）

**GET /v2/models** — 获取可用模型列表

```
请求：无参数

响应 200：
[
  {
    "id": "a1b2c3d4-...",
    "modelKey": "claude-3-sonnet",
    "displayName": "Claude 3.5 Sonnet",
    "provider": "anthropic",
    "capabilities": ["creative_writing", "analysis", "extraction", "english", "structured_output"],
    "maxContextTokens": 200000,
    "maxOutputTokens": 8192,
    "costPer1kInput": 0.003000,
    "costPer1kOutput": 0.015000,
    "supportsStreaming": true,
    "isAvailable": true
  },
  {
    "id": "e5f6g7h8-...",
    "modelKey": "deepseek-v3",
    "displayName": "DeepSeek V3",
    "provider": "deepseek",
    "capabilities": ["creative_writing", "chinese", "cheap", "long_context"],
    "maxContextTokens": 128000,
    "maxOutputTokens": 8192,
    "costPer1kInput": 0.000270,
    "costPer1kOutput": 0.001100,
    "supportsStreaming": true,
    "isAvailable": true
  }
]
```

**GET /v2/models/{modelKey}** — 获取单个模型详情

```
请求：路径参数 modelKey = "deepseek-v3"

响应 200：
{
  "id": "e5f6g7h8-...",
  "modelKey": "deepseek-v3",
  "displayName": "DeepSeek V3",
  "provider": "deepseek",
  "capabilities": ["creative_writing", "chinese", "cheap", "long_context"],
  "maxContextTokens": 128000,
  "maxOutputTokens": 8192,
  "costPer1kInput": 0.000270,
  "costPer1kOutput": 0.001100,
  "supportsStreaming": true,
  "isAvailable": true,
  "priority": 5
}

响应 404：
{ "error": "MODEL_NOT_FOUND", "message": "模型 deepseek-v3 不存在" }
```

#### 3.3.2 任务路由（管理员）

**GET /v2/admin/model-routing** — 获取所有路由规则

```
响应 200：
[
  {
    "taskType": "story_generation",
    "recommendedModel": {
      "id": "e5f6g7h8-...",
      "modelKey": "deepseek-v3",
      "displayName": "DeepSeek V3"
    },
    "fallbackModel": {
      "id": "a1b2c3d4-...",
      "modelKey": "claude-3-sonnet",
      "displayName": "Claude 3.5 Sonnet"
    },
    "routingStrategy": "fixed"
  },
  {
    "taskType": "entity_extraction",
    "recommendedModel": {
      "id": "i9j0k1l2-...",
      "modelKey": "gemini-2-flash",
      "displayName": "Gemini 2.0 Flash"
    },
    "fallbackModel": null,
    "routingStrategy": "cost_optimized"
  }
]
```

**PUT /v2/admin/model-routing/{taskType}** — 更新路由规则

```
请求：
{
  "recommendedModelId": "e5f6g7h8-...",
  "fallbackModelId": "a1b2c3d4-...",
  "routingStrategy": "fixed",
  "configJson": null
}

响应 200：
{
  "taskType": "story_generation",
  "recommendedModel": { "id": "e5f6g7h8-...", "modelKey": "deepseek-v3", "displayName": "DeepSeek V3" },
  "fallbackModel": { "id": "a1b2c3d4-...", "modelKey": "claude-3-sonnet", "displayName": "Claude 3.5 Sonnet" },
  "routingStrategy": "fixed"
}

响应 400：
{ "error": "INVALID_MODEL", "message": "指定的模型不存在或不可用" }
```

#### 3.3.3 用户偏好

**GET /v2/users/me/model-preferences** — 获取当前用户的模型偏好

```
响应 200：
[
  {
    "taskType": "story_generation",
    "preferredModel": {
      "id": "a1b2c3d4-...",
      "modelKey": "claude-3-sonnet",
      "displayName": "Claude 3.5 Sonnet"
    },
    "systemDefault": {
      "id": "e5f6g7h8-...",
      "modelKey": "deepseek-v3",
      "displayName": "DeepSeek V3"
    }
  },
  {
    "taskType": "refine",
    "preferredModel": null,
    "systemDefault": {
      "id": "a1b2c3d4-...",
      "modelKey": "claude-3-sonnet",
      "displayName": "Claude 3.5 Sonnet"
    }
  }
]
```

**PUT /v2/users/me/model-preferences/{taskType}** — 设置偏好

```
请求：
{ "preferredModelId": "a1b2c3d4-..." }

响应 200：
{
  "taskType": "story_generation",
  "preferredModel": {
    "id": "a1b2c3d4-...",
    "modelKey": "claude-3-sonnet",
    "displayName": "Claude 3.5 Sonnet"
  }
}
```

**DELETE /v2/users/me/model-preferences/{taskType}** — 重置为系统默认

```
响应 204：无内容
```

#### 3.3.4 用量统计

**GET /v2/users/me/model-usage** — 用量汇总

```
请求参数：
  ?period=30d          // 时间范围：7d / 30d / 90d / all
  &groupBy=model       // 分组维度：model / task_type / day

响应 200：
{
  "period": "30d",
  "totalInputTokens": 1250000,
  "totalOutputTokens": 380000,
  "totalCost": 12.450000,
  "totalRequests": 342,
  "successRate": 0.985,
  "breakdown": [
    {
      "key": "deepseek-v3",
      "displayName": "DeepSeek V3",
      "inputTokens": 800000,
      "outputTokens": 250000,
      "cost": 1.230000,
      "requests": 210,
      "avgLatencyMs": 1200
    },
    {
      "key": "claude-3-sonnet",
      "displayName": "Claude 3.5 Sonnet",
      "inputTokens": 450000,
      "outputTokens": 130000,
      "cost": 11.220000,
      "requests": 132,
      "avgLatencyMs": 3500
    }
  ]
}
```

**GET /v2/users/me/model-usage/details** — 详细调用日志

```
请求参数：
  ?page=0&size=20
  &taskType=story_generation    // 可选过滤
  &modelKey=deepseek-v3         // 可选过滤

响应 200：
{
  "content": [
    {
      "id": "log-uuid-...",
      "modelKey": "deepseek-v3",
      "modelDisplayName": "DeepSeek V3",
      "taskType": "story_generation",
      "storyTitle": "星际迷途",
      "inputTokens": 3200,
      "outputTokens": 1500,
      "latencyMs": 1450,
      "costEstimate": 0.002514,
      "success": true,
      "createdAt": "2026-02-17T14:30:00Z"
    }
  ],
  "totalElements": 342,
  "totalPages": 18,
  "number": 0
}
```

#### 3.3.5 A/B 对比生成

**POST /v2/stories/{storyId}/compare-models** — 双模型对比

```
请求：
{
  "taskType": "manuscript_writing",
  "modelKeyA": "deepseek-v3",
  "modelKeyB": "claude-3-sonnet",
  "messages": [
    { "role": "system", "content": "你是一位小说写作助手..." },
    { "role": "user", "content": "请续写以下场景：林远站在悬崖边..." }
  ]
}

响应 200：
{
  "resultA": {
    "modelKey": "deepseek-v3",
    "modelDisplayName": "DeepSeek V3",
    "content": "林远深吸一口气，脚下的碎石簌簌滑落...",
    "inputTokens": 1200,
    "outputTokens": 800,
    "latencyMs": 1100,
    "costEstimate": 0.001204
  },
  "resultB": {
    "modelKey": "claude-3-sonnet",
    "modelDisplayName": "Claude 3.5 Sonnet",
    "content": "风从谷底涌上来，带着潮湿的泥土气息...",
    "inputTokens": 1200,
    "outputTokens": 750,
    "latencyMs": 2800,
    "costEstimate": 0.014850
  }
}
```

### 3.4 前端设计

#### 3.4.1 组件结构

```
frontend/src/
├── components/model/
│   ├── ModelSelector.tsx            // 模型选择下拉框（嵌入生成对话框）
│   ├── ModelCard.tsx                // 单个模型信息卡片
│   ├── CostEstimate.tsx             // 生成前成本预估提示
│   └── CapabilityBadge.tsx          // 能力标签徽章
├── pages/settings/
│   └── ModelPreferencesPage.tsx     // 设置 > 模型偏好页面
│       └── TaskModelGrid.tsx        // 任务-模型映射表格
├── pages/story/
│   └── ModelComparisonView.tsx      // A/B 对比侧边栏视图
└── pages/dashboard/
    └── UsageDashboard.tsx           // 用量统计仪表盘
        ├── UsageSummaryCards.tsx     // 汇总卡片（总 Token、总成本等）
        ├── UsageByModelChart.tsx     // 按模型分布饼图
        ├── UsageByTaskChart.tsx      // 按任务类型柱状图
        └── UsageTrendChart.tsx       // 日用量趋势折线图
```

#### 3.4.2 ModelSelector 组件

嵌入到所有 AI 生成对话框中（故事生成、大纲编排、正文续写、润色等），替代当前 `AiChatRequest.modelId` 的简单文本输入。

```tsx
interface ModelSelectorProps {
  taskType: string;                    // 当前任务类型
  value?: string;                      // 选中的 modelKey
  onChange: (modelKey: string) => void;
  showCostEstimate?: boolean;          // 是否显示成本预估
  estimatedInputTokens?: number;       // 预估输入 Token（用于成本计算）
}

// 展示逻辑：
// 1. 默认选中 = 用户偏好 || 系统推荐（带"推荐"标签）
// 2. 下拉列表按 provider 分组，每项显示：
//    - 模型名称
//    - 能力标签（彩色徽章）
//    - 成本指示器（$ / $$ / $$$）
//    - "推荐"标签（如果是系统推荐）
// 3. 底部显示 CostEstimate（预估成本）
```

#### 3.4.3 ModelPreferencesPage

在用户设置中新增"模型偏好"标签页：

```
┌─────────────────────────────────────────────────────────────┐
│  模型偏好设置                                                 │
│                                                              │
│  为每种任务类型选择偏好模型。留空则使用系统推荐。                   │
│                                                              │
│  ┌──────────────┬──────────────┬──────────────┬──────────┐  │
│  │ 任务类型      │ 系统推荐      │ 我的偏好      │ 操作     │  │
│  ├──────────────┼──────────────┼──────────────┼──────────┤  │
│  │ 故事生成      │ DeepSeek V3  │ Claude Sonnet│ [重置]   │  │
│  │ 章节大纲      │ DeepSeek V3  │ —（使用推荐） │          │  │
│  │ 正文续写      │ DeepSeek V3  │ —（使用推荐） │          │  │
│  │ 文本润色      │ Claude Sonnet│ GPT-4o       │ [重置]   │  │
│  │ 实体提取      │ Gemini Flash │ —（使用推荐） │          │  │
│  │ 风格分析      │ Claude Sonnet│ —（使用推荐） │          │  │
│  │ Beta Reader  │ Claude Opus  │ —（使用推荐） │          │  │
│  │ 连续性检查    │ Claude Sonnet│ —（使用推荐） │          │  │
│  │ 摘要生成      │ Gemini Flash │ —（使用推荐） │          │  │
│  └──────────────┴──────────────┴──────────────┴──────────┘  │
└─────────────────────────────────────────────────────────────┘
```

#### 3.4.4 ModelComparisonView

A/B 对比视图，在故事编辑器中以侧边栏形式展示：

```
┌─────────────────────────────────────────────────────────────┐
│  模型对比                                          [关闭]    │
│                                                              │
│  ┌─────────────────────┐  ┌─────────────────────┐          │
│  │ DeepSeek V3         │  │ Claude 3.5 Sonnet   │          │
│  │ 1100ms · $0.0012    │  │ 2800ms · $0.0149    │          │
│  ├─────────────────────┤  ├─────────────────────┤          │
│  │                     │  │                     │          │
│  │ 林远深吸一口气，     │  │ 风从谷底涌上来，     │          │
│  │ 脚下的碎石簌簌滑落…  │  │ 带着潮湿的泥土气息…  │          │
│  │                     │  │                     │          │
│  │                     │  │                     │          │
│  └─────────────────────┘  └─────────────────────┘          │
│                                                              │
│  [采用左侧]              [采用右侧]              [合并编辑]  │
└─────────────────────────────────────────────────────────────┘
```

#### 3.4.5 UsageDashboard

用量仪表盘，展示用户的 AI 调用统计：

- 顶部汇总卡片：总请求数、总 Token 消耗、总成本、成功率
- 按模型分布饼图：直观展示各模型的使用占比
- 按任务类型柱状图：展示不同任务的调用频次
- 日用量趋势折线图：展示近 30 天的 Token 消耗趋势

### 3.5 Prompt 工程

#### 3.5.1 问题

不同模型对 prompt 格式的敏感度不同：

- Claude 系列对 XML 标签格式（`<instructions>...</instructions>`）响应最佳
- GPT 系列对 Markdown 格式和 system message 响应最佳
- DeepSeek 对中文自然语言指令响应最佳，对过度结构化的 prompt 反而效果下降
- Gemini 对简洁直接的指令响应最佳

如果所有模型使用同一套 prompt 模板，会导致部分模型的输出质量下降。

#### 3.5.2 Prompt 适配层设计

在 `AiOrchestrator` 和 gRPC 调用之间引入 Prompt 适配层：

```java
public interface PromptAdapter {
    /**
     * 将通用 prompt 结构适配为特定模型的最优格式
     */
    List<AiChatRequest.Message> adapt(
        List<AiChatRequest.Message> messages,
        String taskType,
        Map<String, Object> context
    );
}

@Component
public class ClaudePromptAdapter implements PromptAdapter {
    @Override
    public List<AiChatRequest.Message> adapt(
            List<AiChatRequest.Message> messages, String taskType, Map<String, Object> context) {
        // Claude 偏好：
        // 1. system message 中使用 XML 标签组织结构
        // 2. 将上下文信息包裹在 <context> 标签中
        // 3. 将指令包裹在 <instructions> 标签中
        // 4. 明确输出格式要求
        // ...
    }
}

@Component
public class DeepSeekPromptAdapter implements PromptAdapter {
    @Override
    public List<AiChatRequest.Message> adapt(
            List<AiChatRequest.Message> messages, String taskType, Map<String, Object> context) {
        // DeepSeek 偏好：
        // 1. 中文自然语言指令，避免过度结构化
        // 2. 将关键约束放在 user message 末尾
        // 3. 简洁的角色设定
        // ...
    }
}

@Component
public class PromptAdapterFactory {
    private final Map<String, PromptAdapter> adapters;

    public PromptAdapter getAdapter(String provider) {
        return adapters.getOrDefault(provider, new DefaultPromptAdapter());
    }
}
```

#### 3.5.3 适配策略矩阵

| 任务类型 | Claude 适配 | GPT 适配 | DeepSeek 适配 |
|----------|-------------|----------|---------------|
| 故事生成 | XML 标签包裹世界观/角色设定，`<tone>` 标签指定基调 | system message 设定角色，Markdown 列表列出约束 | 自然语言描述创作要求，关键约束放末尾 |
| 实体提取 | `<output_format>` 标签指定 JSON schema | function calling / JSON mode | 明确要求"请以 JSON 格式输出" |
| 风格分析 | `<analysis_dimensions>` 列出分析维度 | 编号列表列出分析维度 | 自然语言描述分析要求 |
| 润色 | `<original>` 和 `<instructions>` 分离原文与指令 | 原文用引用块，指令用粗体 | 直接"请根据以下要求润色" |

---

## 4. 与现有代码的集成点

### 4.1 需要修改的文件

| 文件 | 当前状态 | 改造方案 |
|------|----------|----------|
| `backend/.../ai/AiService.java` | 直接调用 `AiGatewayGrpcClient`，硬编码模型选择逻辑 | 保留为轻量级门面，内部委托给 `AiOrchestrator`。`chat()` 方法中的模型选择逻辑迁移到 `ModelRoutingService` |
| `backend/.../integration/AiGatewayGrpcClient.java` | `chatCompletions()` 接受 `model` 字符串参数 | 无需修改接口签名，`AiOrchestrator` 传入 `ResolvedModel.modelKey()` 即可 |
| `backend/.../ai/AiController.java` | `/v1/ai/models`、`/v1/ai/chat`、`/v1/ai/refine` | 保留 v1 接口兼容，新增 `/v2/models` 等接口在 `ModelRoutingController` 中 |
| `backend/.../story/StoryService.java` | `refineStory()` / `refineCharacter()` 直接调用 `aiService.refine()` | 改为调用 `aiOrchestrator.generate()`，传入 `taskType = "refine"` |
| `backend/.../world/WorldService.java` | `refineWorldField()` 直接调用 `aiService.refine()` | 同上，改为通过 `AiOrchestrator` 调用 |
| `backend/.../story/StoryController.java` | 注入 `AiService` 用于 AI 相关操作 | 改为注入 `AiOrchestrator` |
| `backend/.../world/WorldController.java` | 注入 `AiService` 用于 AI 相关操作 | 改为注入 `AiOrchestrator` |
| `backend/.../ai/dto/AiChatRequest.java` | `modelId` 字段由前端传入 | 保留字段用于用户临时指定模型（覆盖偏好），`AiOrchestrator` 优先使用此值 |

### 4.2 与其他 v2 模块的协作

| 模块 | 协作方式 |
|------|----------|
| **01-上下文记忆系统** | 实体提取任务使用 `task_type = "entity_extraction"`，路由到快速廉价模型（如 Gemini Flash）；Embedding 任务使用 `task_type = "embedding"`，路由到向量模型 |
| **02-风格画像** | 风格分析任务使用 `task_type = "style_analysis"`，路由到分析能力强的模型（如 Claude Sonnet）；风格画像生成后，`PromptAdapter` 将风格约束注入到创作类 prompt 中 |
| **03-Beta-Reader** | Beta Reader 审读使用 `task_type = "beta_reader"`，路由到综合能力最强的模型（如 Claude Opus）；连续性检查使用 `task_type = "continuity_check"` |

### 4.3 迁移策略

采用渐进式迁移，确保 v1 接口不中断：

1. **Phase 1**：创建 `model` 包，实现 `ModelRegistryService`（同步模型列表）和 `ModelRoutingService`（路由逻辑），数据库建表
2. **Phase 2**：实现 `AiOrchestrator`，在内部调用 `ModelRoutingService` + `AiGatewayGrpcClient`，但暂不替换现有调用链
3. **Phase 3**：逐个将 `StoryService`、`WorldService` 等的 `AiService` 调用替换为 `AiOrchestrator` 调用
4. **Phase 4**：实现前端 `ModelSelector`、`ModelPreferencesPage`、`UsageDashboard`
5. **Phase 5**：实现 A/B 对比功能和 Prompt 适配层

---

## 5. 实施注意事项

### 5.1 模型可用性变化

- ai-service 的模型列表可能随时变化（新模型上线、旧模型下线、临时维护）
- `ModelRegistryService.syncFromGateway()` 每 5 分钟同步一次，但在用户发起生成请求时，如果路由到的模型已不可用，应实时 fallback 而非等待下次同步
- 前端 `ModelSelector` 应在打开时实时拉取模型列表，而非依赖缓存

### 5.2 成本追踪精度

- `cost_per_1k_input` / `cost_per_1k_output` 来自模型注册表的静态配置，实际计费由 AIENIE pay-service 通过 `EconomyService` 处理
- `model_usage_logs.cost_estimate` 仅为预估值，用于用户参考，不作为实际扣费依据
- 需要定期与 ai-service 的定价信息同步，避免预估值与实际扣费偏差过大

### 5.3 速率限制

- 不同模型 provider 有不同的速率限制（RPM / TPM）
- A/B 对比功能会同时发起两个请求，需注意不要触发速率限制
- 建议在 `AiOrchestrator` 中实现简单的令牌桶限流，按 provider 维度控制并发

### 5.4 优雅降级

- 当所有模型（主模型 + fallback）均不可用时，应返回明确的错误信息而非无限重试
- 前端应展示降级提示："当前 AI 服务繁忙，已自动切换到备选模型"
- 记录降级事件到 `model_usage_logs`，便于运维监控

### 5.5 数据一致性

- `model_registry` 表是本地缓存，真实模型可用性以 ai-service 为准
- 用户偏好中引用的模型如果被删除或下线，路由逻辑应自动跳过并回退到系统默认
- 管理员修改路由规则后应立即生效，无需重启服务（数据库驱动，非配置文件）

### 5.6 安全考虑

- 模型注册表的写操作（新增/修改/删除模型、修改路由规则）仅限管理员角色
- 用户只能修改自己的偏好，不能修改其他用户的偏好
- `model_usage_logs` 包含用户行为数据，需遵循数据保留策略
- A/B 对比请求的成本是普通请求的两倍，前端应明确提示用户

---

## 6. 验收标准

### 6.1 功能验收

| 编号 | 验收项 | 验收条件 |
|------|--------|----------|
| AC-1 | 模型注册表同步 | 系统启动后 5 分钟内自动从 ai-service 同步模型列表；新模型上线后下次同步自动出现在注册表中 |
| AC-2 | 任务级路由 | 不同任务类型（故事生成 vs 实体提取 vs 润色）使用不同模型，可通过 `model_usage_logs` 验证 |
| AC-3 | 用户偏好覆盖 | 用户设置偏好后，对应任务类型使用偏好模型；删除偏好后回退到系统默认 |
| AC-4 | Fallback 降级 | 模拟主模型不可用（标记 `is_available = false`），系统自动切换到 fallback 模型，生成不中断 |
| AC-5 | 成本预估 | 生成对话框中显示预估成本；生成完成后 `model_usage_logs` 记录实际 Token 消耗和成本 |
| AC-6 | A/B 对比 | 选择两个模型对同一任务生成，侧边栏展示两个结果，用户可选择采用其中一个 |
| AC-7 | 用量统计 | 用量仪表盘正确展示按模型/任务类型/时间的统计数据 |
| AC-8 | 向后兼容 | v1 接口 `/v1/ai/chat`、`/v1/ai/refine` 正常工作，行为不变 |

### 6.2 非功能验收

| 编号 | 验收项 | 验收条件 |
|------|--------|----------|
| NF-1 | 路由延迟 | `ModelRoutingService.resolveModel()` 耗时 < 5ms（数据库查询 + 缓存） |
| NF-2 | Fallback 延迟 | 主模型失败到 fallback 模型开始调用的切换时间 < 100ms |
| NF-3 | 同步稳定性 | `syncFromGateway()` 在 ai-service 不可用时不抛异常，仅记录警告日志 |
| NF-4 | 并发安全 | A/B 对比的两个并行请求互不干扰，各自独立记录用量 |
| NF-5 | 数据完整性 | `model_usage_logs` 在任何情况下（成功/失败/fallback）都有记录，无遗漏 |
